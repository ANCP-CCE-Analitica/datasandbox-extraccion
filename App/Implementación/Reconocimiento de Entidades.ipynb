{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"  padding: 10px;text-align: center;\" class='row'>\n",
    "<div style=\"float:left;width: 10%;\" class='column'><a href=\"https://datos.gov.co/\"><img alt=\"Logo DataSandbox\"  src=\"https://github.com/DataSandbox/Plantilla-Publicacion-Resultados/raw/main/App/logdat.JPG\" style=\"width: 100px;\"></a></div>\n",
    "    <div style=\"float:left;width: 80%;\" class='column'>\n",
    "        <h1>EXTRACCIÓN DE INFORMACIÓN EN DOCUMENTOS DE PROCESOS DE CONTRATACIÓN PÚBLICA\n",
    "        </h1> \n",
    "    </div>\n",
    " <div style=\"float:left;width: 10%;\" class='column'><a href=\"https://www.colombiacompra.gov.co/\" target=\"_blank\"><img class=\"float-right\" src=\"https://raw.githubusercontent.com/ANCP-CCE-Analitica/datasandbox-extraccion/main/logo_ancp_cce_web.png\" style=\"width: 200px;\"></a></div>\n",
    "    </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uso de Text Analytics\n",
    "\n",
    "Posterior a la creación del corpus, una lectura exitosa de 10368 contratos, procedemos a extraer la entidades con Text Analytics. El resultado es una base con el UID del proceso, el texto extraido, el texto limpio y las entidades reconcidas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "99fc34df-8f48-4b39-9f4f-18a803ad8c84",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "spark.conf.set (\n",
    "  \"fs.azure.account.key.dlscontratacionpuproceso.dfs.core.windows.net\",\n",
    "  dbutils.secrets.get (scope = \"contratacionpuproceso-key-vault-secrets\", key = \"StorageAccountKey\")\n",
    ")\n",
    "file_location = \"abfss://demo2@dlscontratacionpuproceso.dfs.core.windows.net/Descarga SECOP I/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4d943364-1c5e-45fd-bb12-3a01f3a05d87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DFText_total=spark.read.parquet(file_location+'/Descarga SECOP I/MUESTRA/DFText_total.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e44099e9-1ac2-4e53-91ee-9ba4f4c0b65e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DFText_total=DFText_total.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "525b4ca1-5e5a-417e-947d-e3cae87e513b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DFText_total_processed=DFText_total[['UID','Text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "21d194b2-82b8-4db0-bcb6-a090fb1d03d4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Antes, una estandarización del texto muy sencilla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "18dbf10a-68aa-4530-9dbf-683398fe3170",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "New_corpus=[]\n",
    "for i in DFText_total_processed.Text:\n",
    "      New_corpus.append(i.replace('\\n',' ').replace('\\t',' ').replace('-','').upper())\n",
    "DFText_total_processed['clean_text']=New_corpus\n",
    "  \n",
    "                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de Text Analytics\n",
    "Creamos una base por proceso que determina las entidades sus categorías y subcategorías y nos indica donde está cada entidad encontrada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c2f47c0e-05da-4e4b-90d8-d2ae59181e5a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install azure.ai.textanalytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e2394f98-85f3-4484-b8e7-5350965b534f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "key = \"08cc21d9ec66400cb32024f4dce8842f\"\n",
    "endpoint = \"https://cog-text-contratacionpublica-procesos.cognitiveservices.azure.com/\"\n",
    "\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Authenticate the client using your key and endpoint \n",
    "def authenticate_client():\n",
    "    ta_credential = AzureKeyCredential(key)\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "            endpoint=endpoint, \n",
    "            credential=ta_credential)\n",
    "    return text_analytics_client\n",
    "\n",
    "client = authenticate_client()\n",
    "\n",
    "# Example function for recognizing entities from text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3f9bc5fb-c37c-4ef3-90ad-3fa90251e27e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def entity_recognition_example(client):\n",
    "\n",
    "    try:\n",
    "        documents = [\"En el monte de la china una china se perdió con 500 millones de pesos y la policía no la encontró...\"]\n",
    "        result = client.recognize_entities(documents = documents)[0]\n",
    "\n",
    "        print(\"Named Entities:\\n\")\n",
    "        for entity in result.entities:\n",
    "            print(\"\\tText: \\t\", entity.text, \"\\tCategory: \\t\", entity.category, \"\\tSubCategory: \\t\", entity.subcategory,\n",
    "                    \"\\n\\tConfidence Score: \\t\", round(entity.confidence_score, 2), \"\\tLength: \\t\", entity.length, \"\\tOffset: \\t\", entity.offset, \"\\n\")\n",
    "\n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))\n",
    "entity_recognition_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "02197a8e-0062-44bb-a4d2-8ee54696806c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "entities=dict()\n",
    "for num,i in enumerate(DFText_total_processed['clean_text']):\n",
    "  num_max=int(np.ceil(len(i)/5120))\n",
    "  documents=[]\n",
    "  if num%100==0:\n",
    "    print(num)\n",
    "  for j in range(num_max):\n",
    "    documents.append(i[j*5120:(j+1)*5120])\n",
    "  num_max_2=int(np.ceil(len(documents)/5))\n",
    "  documents_2=[]\n",
    "  for j in range(num_max_2):\n",
    "    documents_2.append(documents[j*5:(j+1)*5])\n",
    "  other_list=dict()\n",
    "  Texto=[]\n",
    "  Categoría=[]\n",
    "  Subcategoría=[]\n",
    "  Confianza=[]\n",
    "  Longitud=[]\n",
    "  Compensación=[]\n",
    "  for h in documents_2:\n",
    "    for k in client.recognize_entities(documents = h):\n",
    "      for entity in k.entities:\n",
    "        Texto.append(entity.text)\n",
    "        Categoría.append(entity.category)\n",
    "        Subcategoría.append(entity.subcategory)\n",
    "        Confianza.append(round(entity.confidence_score, 2))\n",
    "        Compensación.append(entity.offset)\n",
    "        Longitud.append(entity.length)\n",
    "      other_list['Texto']=Texto\n",
    "      other_list['Categoría']=Categoría\n",
    "      other_list['Subcategoría']=Subcategoría\n",
    "      other_list['Confianza']=Confianza\n",
    "      other_list['Longitud']=Longitud\n",
    "      other_list['Compensación']=Compensación    \n",
    "  entities[num]=other_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una visualización de lo obtenido en el contrato 10.000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9492e74b-57cc-431d-9879-a3059523e4cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(entities[10000]).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "86174610-e4e4-4c10-967c-0906062a391a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DFText_total_processed['Entidades']=entities.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "095cc644-096d-442c-852f-d255466cab7a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DFText_total_processedspark=spark.createDataFrame(DFText_total_processed)\n",
    "DFText_total_processedspark.write.parquet(file_location+'/Resultado/DFText_total_entities_total.parquet',mode='overwrite')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Text Analytics (3)",
   "notebookOrigID": 2135267827830116,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
